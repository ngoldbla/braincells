# === KSU Research Configuration ===
# Contact ngoldbla@kennesaw.edu for institutional tokens

# === Mandatory ===
HF_TOKEN=           # Institutional or personal token from https://huggingface.co/settings/tokens

# === Optional cloud providers ===
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
# or another Inference Endpoint:  MODEL_ENDPOINT_URL=https://....

# === Local model ===
# Pick ONE from the table below. Larger models need more RAM/VRAM.
# phi:2.7b (4GB), gemma:2b (6GB), mistral:7b (8GB), gpt-oss:20b (12-14GB), gpt-oss:120b (30-40GB)
OLLAMA_MODEL=gpt-oss:20b

# If you don't want any local model (e.g. you'll use OpenAI only), set:
# DISABLE_OLLAMA=true
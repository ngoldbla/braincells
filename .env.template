# Brain Cells Configuration
# Copy this file to .env and fill in your values

# === RECOMMENDED: Hugging Face Token ===
# Get your free token at: https://huggingface.co/settings/tokens
# This unlocks access to thousands of AI models and faster inference
HF_TOKEN=

# === OPTIONAL: Additional AI Providers ===
# Add any of these if you want to use cloud providers instead of/in addition to local models

# OpenAI API Key (for GPT models)
OPENAI_API_KEY=

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=

# === OPTIONAL: Local Model Selection ===
# Uncomment and change to use a different local model
# Default is gpt-oss:20b which provides best quality but needs 14GB RAM
# OLLAMA_MODEL=llama3.2     # 8GB RAM, fast
# OLLAMA_MODEL=mistral      # 8GB RAM, balanced
# OLLAMA_MODEL=phi          # 4GB RAM, lightweight

# === OPTIONAL: Disable Local Models ===
# Set to true if you only want to use cloud providers (requires HF_TOKEN or API keys above)
# DISABLE_OLLAMA=false

# === OPTIONAL: Custom Model Endpoint ===
# Use your own model endpoint (must be OpenAI API compatible)
# MODEL_ENDPOINT_URL=https://your-endpoint.com
# MODEL_ENDPOINT_NAME=your-model-name